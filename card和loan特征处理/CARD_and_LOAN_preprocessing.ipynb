{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROADMAP\n",
    "\n",
    "**[<font color='green'>1. 读取所需API与数据</font>](#link1)**\n",
    "<br>**[<font color='green'>2. 去重</font>](#link2)**\n",
    "- [Function: Duplicates( )](#link2.1)\n",
    "- [Execution: Duplicates( )](#link2.2)\n",
    "\n",
    "<br>**[<font color='green'>3. 处理多个查询时间问题</font>](#link3)**\n",
    "- [Function: Ctime( )](#link3.1)\n",
    "- [Execution: Ctime( )](#link3.2)\n",
    "\n",
    "<br>**[<font color='green'>4. 数据初报告</font>](#link4)**\n",
    "- [Function: Exploration( )](#link4.1)\n",
    "- [Execution: Exploration( )](#link4.2)\n",
    "\n",
    "<br>**[<font color='green'>5. 基于缺失与异常的衍生</font>](#link5)**\n",
    "\n",
    "<br>**[<font color='green'>6. 丢弃缺失过多特征</font>](#link6)**\n",
    "- [Class: DropNA( )](#link5.1)\n",
    "- [Execution: DropNA( )](#link5.2)\n",
    "\n",
    "<br>**[<font color='darkred'>6. Feature Engineering</font>](#link6)**\n",
    "- [6.0 ID, Observation Point and Label(y)](#link6.0)\n",
    "    - Extract ID, Observation Point and y from JIBEN_sheet\n",
    "    - Merge with Loan, Card and Stdcard   \n",
    "    \n",
    "- [6.1 Classify the Feature Types](#link6.1)\n",
    "    - Check time range and the corresponding samples\n",
    "    - Classification\n",
    "- [6.2 Loan Features Deep Mining](#link6.2)    \n",
    "- [6.3 Fill NA](#link6.3)\n",
    "    - dates & months: 1900.01.01 or 1900.01\n",
    "    - amounts: 0\n",
    "    - counts: ?\n",
    "    - types: ?\n",
    "- [6.4 Generate](#link6.4)\n",
    "    - nunique of financeorg\n",
    "    - whether contain 浦发\n",
    "    - latest24state\n",
    "    - sum of amounts\n",
    "- [6.5 Cross \\& Dot Products](#link6.5)\n",
    "- [6.6 Time Filter](#link6.5)\n",
    "\n",
    "**<font color='red'>OUTLIERS IN JIBEN</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='link1'>**<font color='green'>1. Import API, Read Data and Reduce Memory</font>**</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import h5py\n",
    "import missingno as msn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import sklearn\n",
    "# sklearn.show_versions()\n",
    "\n",
    "import Memory as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce Memory Usage Function Reports:\n",
      "Memory usage of dataframe is 1259.57 MB\n",
      "Memory usage after optimization is: 869.85 MB\n",
      "Decreased by 30.9%\n",
      " \n",
      "Reduce Memory Usage Function Reports:\n",
      "Memory usage of dataframe is 1448.35 MB\n",
      "Memory usage after optimization is: 1024.19 MB\n",
      "Decreased by 29.3%\n",
      " \n",
      "time cost 64.83seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "jiben = pd.read_csv('refer/jiben_vars_new_20200424.csv',skiprows=list(range(779441,779509)),\n",
    "                     encoding=\"ISO-8859-1\",error_bad_lines=False,low_memory=False)\n",
    "jiben = mm.reduce_mem_usage(jiben)\n",
    "strange_bad = jiben['bad'].value_counts().index[-1]\n",
    "jiben['bad'].replace({strange_bad:'N'},inplace=True)\n",
    "jiben['bad'].fillna('N',inplace=True)\n",
    "\n",
    "# card = pd.read_csv('refer/kw_poc_card_20200424.csv')\n",
    "# card = mm.reduce_mem_usage(card)\n",
    "\n",
    "loan = pd.read_csv('refer/kw_poc_loan_20200424.csv')\n",
    "loan = mm.reduce_mem_usage(loan)\n",
    "\n",
    "end = time.time()\n",
    "print('time cost {}seconds'.format(np.round(end-start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='link2'>**<font color='green'>2.Check Drop and Save Duplicated Samples</font>**</a>\n",
    "- <a id='link2.1'>2.1 Function: Duplicates( )</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Duplicates(i,return_dict,df,job_name):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    n,m = df.shape[0],df.shape[1] \n",
    "    \n",
    "    # Check Duplicates\n",
    "    dup_samples_cond = df.duplicated(keep='first')==True\n",
    "    kept_cond = df.duplicated(keep='first')==False\n",
    "    dup_samples = df.loc[dup_samples_cond]\n",
    "    dup_sample_cnt = dup_samples.shape[0]\n",
    "    \n",
    "    print('abondon completely duplicated samples')\n",
    "    print('find {} duplicate rows'.format(dup_sample_cnt))\n",
    "    \n",
    "    end = time.time()\n",
    "    print('{} duplicates processing finished, time cost {}seconds'.format(job_name,np.round(end-start,2)))\n",
    "    \n",
    "    return_dict[i]=[df,dup_samples]\n",
    "    \n",
    "    return df,dup_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='link2'>**<font color='green'>2.Check Drop and Save Duplicated Samples</font>**</a>\n",
    "- <a id='link2.1'>2.2 Execution: Duplicates( )</a>\n",
    "    - **Multiprocessing**\n",
    "    - **about 10~12min**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "all_sheets = [loan]\n",
    "sheets_name = ['loan']\n",
    "if __name__ == '__main__':\n",
    "    manager = mp.Manager()\n",
    "    return_dict = manager.dict()\n",
    "    jobs = []\n",
    "    for i in range(1):\n",
    "        p = mp.Process(target=Duplicates, args=(i,return_dict,all_sheets[i],sheets_name[i]))\n",
    "        jobs.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for proc in jobs:\n",
    "        proc.join()\n",
    "        \n",
    "end = time.time()\n",
    "print('total time cost of duplicates processing takes {}seconds'.format(np.round(end-start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dup = return_dict[0]\n",
    "del loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dup[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='link3'>**<font color='green'>3. Deal With Multiple Ctime</font>**</a>\n",
    "- <a id='link3.1'>3.1 Function: Ctime( )</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctime(procnum,return_dict,job_name,df,\n",
    "          id_name='id',index_name='index'):\n",
    "    \n",
    "    start = time.time()\n",
    "    # find all ids have multiple ctimes\n",
    "    group = df.groupby(id_name)['ctime'].nunique()\n",
    "    cond = group>1\n",
    "    ids = group.loc[cond].index\n",
    "    \n",
    "    \n",
    "    for i in ids:\n",
    "        cond = df[id_name]==i\n",
    "        \n",
    "        process_df = df.loc[cond]\n",
    "        df.drop(process_df.index,inplace=True)\n",
    "        process_cond = process_df.sort_values(by=['ctime',index_name],\n",
    "                                              ascending=False).duplicated(subset=index_name,\n",
    "                                                                          keep='first')==False\n",
    "        process_df = process_df.loc[process_cond]\n",
    "        df = pd.concat([df,process_df],axis=0)\n",
    "        \n",
    "    return_dict[procnum] = df\n",
    "    \n",
    "    end = time.time()\n",
    "    print('dealing ctime of {} takes {}seconds'.format(job_name,np.round(end-start,2)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='link3'>**<font color='green'>3. Deal With Multiple Ctime</font>**</a>\n",
    "- <a id='link3.1'>3.2 Execution: Ctime( )</a>\n",
    "- **about 8~10 mins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "all_sheets = [card_dup[0]]\n",
    "sheets_name = ['card']\n",
    "if __name__ == '__main__':\n",
    "    manager = mp.Manager()\n",
    "    return_dict = manager.dict()\n",
    "    jobs = []\n",
    "    for i in range(1):\n",
    "        p = mp.Process(target=ctime, args=(i,return_dict,sheets_name[i],all_sheets[i]))\n",
    "        jobs.append(p)\n",
    "        p.start()\n",
    "    \n",
    "    for proc in jobs:\n",
    "        proc.join()\n",
    "        \n",
    "end = time.time()\n",
    "print('total time cost of ctime processing spend {}seconds'.format(np.round(end-start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctime_card = return_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_dup[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del card_dup\n",
    "del return_dict,all_sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctime_card.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orange'>**Loan Features Classification**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_loan=['id']\n",
    "types_loan = ['financeorg','financetype','type','currency','guaranteetype']\n",
    "dates_loan = ['opendate','enddate','stateenddate','stateendmonth',\n",
    "         'scheduledpaymentdate','recentpaydate']\n",
    "months_loan = ['latest24monthpaymentbeginmonth','latest24monthpaymentendmonth',\n",
    "          'latest5yearoverduebeginmonth','latest5yearoverdueendmonth']\n",
    "counts_loan = ['paymentrating','paymentcyc','remainpaymentcyc','curroverduecyc']\n",
    "states_loan = ['state','class5state','latest24state']\n",
    "amounts_loan = ['creditlimitamount','balance','scheduledpaymentamount',\n",
    "           'actualpaymentamount','curroverdueamount','overdue31to60amount',\n",
    "           'overdue61to90amount','overdue91to180amount','overdueover180amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orange'>**Card Features Classification**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_card = ['id']\n",
    "types_card = ['financeorg','financetype','currency','guaranteetype']\n",
    "dates_card = ['opendate','stateenddate','stateendmonth','scheduledpaymentdate','recentpaydate']\n",
    "months_card = ['latest24monthpaymentbeginmonth','latest24monthpaymentendmonth',\n",
    "          'latest5yearoverduebeginmonth','latest5yearoverdueendmonth']\n",
    "counts_card = ['curroverduecyc']\n",
    "states_card = ['state','latest24state']\n",
    "amounts_card = ['creditlimitamount','sharecreditlimitamount','usedcreditlimitamount',\n",
    "           'latest6monthusedavgamount','usedhighestamount','scheduledpaymentamount',\n",
    "           'actualpaymentamount','curroverdueamount','overdue31to60amount',\n",
    "           'overdue61to90amount','overdue91to180amount','overdueover180amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='link4'>**<font color='green'>4. 数据初报告</font>**</a>\n",
    "- <a id='link4.1'>4.1 Function: Exploration( )</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Exploration(df,almost_empty=0.9):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    n,m = df.shape[0],df.shape[1] \n",
    "    dtypes = pd.DataFrame(df.dtypes)\n",
    "    \n",
    "    # Missing Values, Nunique, Data Type\n",
    "    dtypes.columns = ['data types']\n",
    "    null = pd.DataFrame(df.isnull().sum())\n",
    "    null.columns = ['none cnt']\n",
    "    null['none percentage'] = (null['none cnt']/n).apply(lambda x: \"{0:.2f}%\".format(x * 100))\n",
    "    null['empty'] = 1*(null['none cnt']==n)\n",
    "    null['>='+str(int(almost_empty*100))+'% empty']=1*(null['none cnt']/n>=almost_empty)\n",
    "    \n",
    "    nunique = pd.DataFrame(df.nunique())\n",
    "    nunique.columns = ['n_unique']\n",
    "    \n",
    "    exploration = pd.concat([dtypes,null,nunique],axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print('function finished one time, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "    \n",
    "#   return [exploration,total_dup_cnt,unique_dup_cnt]\n",
    "    return exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='link4'>**<font color='green'>4. Data Report</font>**</a>\n",
    "- <a id='link4.1'>4.2 Execution: Exploration( )</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiben_ep = Exploration(jiben)\n",
    "card_ep = Exploration(ctime_card)\n",
    "loan_ep = Exploration(ctime_loan)\n",
    "stdcard_ep = Exploration(ctime_stdcard)\n",
    "query_ep = Exploration(ctime_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='link6'>**<font color='darkred'>6. Feature Engineering</font>**</a>\n",
    "- <a id='link6.0'>**6.0 Extract ID, Observation Point and Label**</a>\n",
    "    - **Extract from Jiben sheet**\n",
    "    - **Merge with Loan, Card and Stdcard**\n",
    "    \n",
    "<br><font color='red'>**Warning: `Inner` method is only applied to little sample version. For all data, method is `right` or `left`**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_point = jiben[['id','bad','nasrdw_recd_date']]\n",
    "loan_merged = pd.merge(right = loan, \n",
    "                       left = observation_point,\n",
    "                       how='right',\n",
    "                       on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_point = jiben[['id','bad','nasrdw_recd_date']]\n",
    "card_merged = pd.merge(right = card,\n",
    "                       left = observation_point,\n",
    "                       how='right',\n",
    "                       on='id')\n",
    "# del ctime_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = loan_merged['bad'].isin(['G','B','N'])\n",
    "loan_filtered = loan_merged.loc[cond1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4351772, 37)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loan_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='link5'>**<font color='green'>5. 基于缺失与异常的衍生</font>**</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NA_OL_Records_Detailed(df,target_cols):\n",
    "    \n",
    "    start = time.time()\n",
    "        \n",
    "    df['ol_neg'] = (df[target_cols].fillna(0)<0).sum(axis=1)\n",
    "    df['na_record'] = df.isnull().sum(axis=1)\n",
    "    \n",
    "    cols = target_cols[:7]\n",
    "    \n",
    "    thres = list(df[cols].fillna(0).quantile(0.99).values)\n",
    "    print(thres)\n",
    "    \n",
    "    ol_mark = 1*(df[cols].fillna(0)>=thres)\n",
    "\n",
    "    ol_cols = [i+'_99ol' for i in cols]\n",
    "\n",
    "    df[ol_cols] = ol_mark\n",
    "    \n",
    "    ol_records_g = df.groupby('id')[['na_record']+['ol_neg']+ol_cols].sum()\n",
    "    \n",
    "    values = pd.DataFrame(ol_records_g.values)\n",
    "    values.columns = ['na_record']+['ol_neg']+ol_cols\n",
    "    ol_records_df = pd.concat([pd.DataFrame(ol_records_g.index),\n",
    "                               values],axis=1)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('na and outliers record takes {}seconds'.format(np.round(end-start,2)))\n",
    "    return ol_records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_loan_df = NA_OL_Records_Detailed(loan_filtered,amounts_loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_loan_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_loan_df.to_csv('Loan_processed/loan_ol.csv',index=False,encoding='GBK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**填充缺失值**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillNA():\n",
    "    \n",
    "    def __init__(self,df,dates,months,types,states,amounts):\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.types = types\n",
    "        self.dates = dates\n",
    "        self.months = months\n",
    "        self.fts = list(df.columns)\n",
    "#        self.counts = counts\n",
    "        self.states = states\n",
    "        self.amounts = amounts\n",
    "        \n",
    "    def checkFeatures(self):\n",
    "        \n",
    "        drop = set(self.dates)-set(self.fts)\n",
    "        self.dates = list(set(self.dates)-drop)\n",
    "                \n",
    "        drop = set(self.months)-set(self.fts)\n",
    "        self.months = list(set(self.months)-drop)            \n",
    "            \n",
    "        drop = set(self.types)-set(self.fts)\n",
    "        self.types = list(set(self.types)-drop)\n",
    "        \n",
    "        drop = set(self.states)-set(self.fts)\n",
    "        self.states = list(set(self.states)-drop)\n",
    "        \n",
    "        drop = set(self.amounts)-set(self.fts)\n",
    "        self.amounts = list(set(self.amounts)-drop)        \n",
    "        \n",
    "    def FillDates(self,value='1900.01.01'):\n",
    "        \n",
    "        for i in self.dates:\n",
    "            self.df[i].fillna(value,inplace=True)\n",
    "        \n",
    "    def FillMonths(self,value='1900.01'):\n",
    "\n",
    "        for i in self.months:\n",
    "            self.df[i].fillna(value,inplace=True)\n",
    "            \n",
    "    def FillAmounts(self,value=0):\n",
    "        \n",
    "        for i in self.amounts:\n",
    "            self.df[i].fillna(value,inplace=True)\n",
    "        \n",
    "    def FillTypes(self,value='nothing'):\n",
    "        for i in self.types:\n",
    "            self.df[i].fillna(value,inplace=True)\n",
    "    \n",
    "    def Fill24States(self,value='*'):\n",
    "        self.df['latest24state'].fillna(value,inplace=True)\n",
    "        \n",
    "    def FillStates(self,value='nothing'):\n",
    "        for i in self.states:\n",
    "            self.df[i].fillna(value,inplace=True)\n",
    "        \n",
    "    def FillCurrOverdueCyc(self,value=0):\n",
    "        self.df['curroverduecyc'].fillna(0,inplace=True)\n",
    "    \n",
    "    def Ignite(self):\n",
    "        self.checkFeatures()\n",
    "        self.FillDates()\n",
    "        self.FillMonths()\n",
    "        self.FillAmounts()\n",
    "        self.FillTypes()\n",
    "        self.Fill24States()\n",
    "        self.FillStates()\n",
    "        self.FillCurrOverdueCyc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill = FillNA(loan_filtered,dates_loan,months_loan,types_loan,states_loan,amounts_loan)\n",
    "fill.Ignite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_fillna = fill.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loan_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='link6'>**<font color='darkred'>6. Feature Engineering</font>**</a>\n",
    "- <a id='link6.2'>**6.2 Loan Features Deep Mining**</a>\n",
    "    - 1.opendate has no missing values, paymentcyc has 461865 missing values\n",
    "    - 2.enddate is calculated by opendate+paymentcyc\n",
    "    - 3&4.if `state=1,5`, then there will be `normal` enddate; if `state=3`, there will be `NA enddate`\n",
    "    - 状态截止日：指你的最新状态更新到什么时间，<=查询时间，一般小一个月\n",
    "    - `'financeorg','financetype','type','currency','guaranteetype'`组合数量53474个，将封装小unique值，其中financeorg有1701个unique值，将进行封装\n",
    "    - 但是financeorg每一个unique值出现的ID频率<1%，如果合并出现频率<1/1000的unique，会造成合并的频率巨大，其他的都<=1%，所以决定暂不处理\n",
    "    - 对其他四个categorical变量中频率小的unique值进行合并\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time Filter**\n",
    "- latest opendate to observation point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeFilter():\n",
    "    \n",
    "    def __init__(self,df):\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.cols = df.columns\n",
    "        \n",
    "    \n",
    "    def ObsTimeReformat(self):\n",
    "        \n",
    "        # Reformat Observation\n",
    "        \n",
    "        start = time.time()\n",
    "        # this is observation start point \n",
    "        obs_split = self.df.astype({'nasrdw_recd_date':str})['nasrdw_recd_date'].str.split(pat='',expand=True)\n",
    "        \n",
    "        year = obs_split.iloc[:,1]+obs_split.iloc[:,2]+obs_split.iloc[:,3]+obs_split.iloc[:,4]\n",
    "        month = obs_split.iloc[:,5]+obs_split.iloc[:,6]\n",
    "        date = obs_split.iloc[:,7]+obs_split.iloc[:,8]\n",
    "        \n",
    "        obs_date = year+'.'+month+'.'+date\n",
    "        self.df['nasrdw_recd_date'] = obs_date\n",
    "        \n",
    "        end = time.time()\n",
    "        print('observation start date reformat finished, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "\n",
    "    def DateDFMerge(self):\n",
    "        \n",
    "        start = time.time()\n",
    "        # find the latest opendate, group by IDs\n",
    "        g1 = self.df.groupby('id')['opendate'].max()\n",
    "        l_opendate_df = pd.DataFrame([g1.index.values,g1.values]).T\n",
    "        l_opendate_df.columns = ['id','latest_opendate']\n",
    "        cond = l_opendate_df.duplicated(keep='first')==False\n",
    "        l_opendate_df = l_opendate_df.loc[cond]\n",
    "        \n",
    "        cond = self.df[['id','nasrdw_recd_date']].duplicated(keep='first')==False\n",
    "        g2 = self.df[['id','nasrdw_recd_date']].loc[cond]\n",
    "        self.window_df = pd.merge(left=l_opendate_df,right=g2,left_on='id',right_on='id',how='outer')\n",
    "        \n",
    "        end = time.time()\n",
    "        print('window df merging finished, time cost {}seconds'.format(np.round(end-start,2)))   \n",
    "        \n",
    "\n",
    "    # WindowFilter() must be run after CtimeReformat()\n",
    "    def WindowLabel(self):\n",
    "        \n",
    "        start = time.time()\n",
    "        obs_split = self.window_df['nasrdw_recd_date'].str.split(pat='.',expand=True)\n",
    "        \n",
    "        year = obs_split.iloc[:,0].astype(int)\n",
    "        month = obs_split.iloc[:,1]\n",
    "        date = obs_split.iloc[:,2]\n",
    "        \n",
    "        self.window_df['window_time1']=(year-2).astype(str)+'.'+month+'.'+date\n",
    "        self.window_df['window_time2']=(year-4).astype(str)+'.'+month+'.'+date\n",
    "        self.window_df['window_time3']=(year-6).astype(str)+'.'+month+'.'+date\n",
    "        \n",
    "        self.window_df['window_label1'] = 1*(self.window_df['latest_opendate']>=self.window_df['window_time1'])\n",
    "        self.window_df['window_label2'] = 1*((self.window_df['latest_opendate']<self.window_df['window_time1'])&(self.window_df['latest_opendate']>=self.window_df['window_time2']))\n",
    "        self.window_df['window_label3'] = 1*((self.window_df['latest_opendate']<self.window_df['window_time2'])&(self.window_df['latest_opendate']>=self.window_df['window_time3']))\n",
    "        self.window_df['window_label4'] = 1*(self.window_df['latest_opendate']<self.window_df['window_time3'])\n",
    "        \n",
    "        self.window_filter_df = pd.merge(left=self.df,\n",
    "                                         right=self.window_df.drop('nasrdw_recd_date',axis=1),\n",
    "                                         left_on='id',\n",
    "                                          right_on='id',\n",
    "                                          how='left')\n",
    "        end = time.time()\n",
    "        print('window label generation and merging finished, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "            \n",
    "    def Ignite(self):\n",
    "        self.ObsTimeReformat()\n",
    "        self.DateDFMerge()\n",
    "        self.WindowLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_loan = TimeFilter(loan_fillna)\n",
    "window_loan.Ignite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_window_g = window_loan.window_df.groupby('id')[['window_label1',\n",
    "                                                     'window_label2',\n",
    "                                                     'window_label3',\n",
    "                                                     'window_label4']].min()\n",
    "loan_window_label = pd.concat([pd.DataFrame(loan_window_g.index.values),\n",
    "                               pd.DataFrame(loan_window_g.values)],axis=1)\n",
    "loan_window_label.columns = ['id','window1','window2','window3','window4']\n",
    "loan_window_label.to_csv('Loan_processed/loan_window.csv',index=False,encoding='GBK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loan_window_g,loan_window_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_window = window_loan.window_filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loan_fillna,window_loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Volatilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Volatilities():\n",
    "    \n",
    "    def __init__(self,df,amounts):\n",
    "        \n",
    "        self.df = df\n",
    "        self.amounts = amounts\n",
    "        self.fts = list(df.columns)\n",
    "    \n",
    "#     def checkFeatures(self):\n",
    "        \n",
    "#         drop = set(self.amounts)-set(self.fts)\n",
    "#         self.amounts = list(set(self.amounts)-drop)  \n",
    "        \n",
    "            \n",
    "    def Range_Amount(self):       \n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        g1 = self.df.groupby('id')[self.amounts].max()\n",
    "        g2 = self.df.groupby('id')[self.amounts].min()\n",
    "        \n",
    "        ids1 = g1.index.values\n",
    "        ids2 = g2.index.values\n",
    "        \n",
    "        values1 = g1.values\n",
    "        values2 = g2.values\n",
    "        \n",
    "        self.max_amount = pd.concat([pd.DataFrame(ids1),\n",
    "                                     pd.DataFrame(values1)],axis=1)\n",
    "        self.min_amount = pd.concat([pd.DataFrame(ids2),\n",
    "                                     pd.DataFrame(values2)],axis=1)\n",
    "        \n",
    "        max_cols = ['max_'+i for i in self.amounts]\n",
    "        min_cols = ['min_'+i for i in self.amounts]\n",
    "        \n",
    "        self.max_amount.columns = ['id']+max_cols\n",
    "        self.min_amount.columns = ['id']+min_cols\n",
    "        \n",
    "        end = time.time()\n",
    "        print('range_creditlimitamount finished, time cost {}seconds'.format(np.round(end-start,2))) \n",
    "        \n",
    "    def StdVariance(self):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        g = self.df.groupby('id')[self.amounts[0]].std()\n",
    "        self.stdvar_df = pd.DataFrame([g.index.values,g.values]).T\n",
    "        self.stdvar_df.columns=['id','std_whole_'+self.amounts[0]]\n",
    "        for i in self.amounts[1:]:\n",
    "            g = self.df.groupby('id')[i].std()\n",
    "            var = pd.DataFrame([g.index.values,g.values]).T\n",
    "            var.columns = ['id','stdvar_'+i]\n",
    "            self.stdvar_df = pd.merge(left=self.stdvar_df,right=var,on='id',how='outer')\n",
    "        self.stdvar_df.fillna(0,inplace=True)\n",
    "\n",
    "        end = time.time()\n",
    "        print('stdvariance finished, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "        \n",
    "    def Rate(self):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        denominator = self.df['creditlimitamount']\n",
    "        \n",
    "        numerator_cols = self.amounts[1:]\n",
    "        numerator = self.df[numerator_cols]\n",
    "        \n",
    "        rates_df = numerator.div(denominator,axis=0)\n",
    "        rates_df.fillna(0,inplace=True)\n",
    "        \n",
    "        rates_df = pd.concat([self.df['id'],rates_df],axis=1)\n",
    "        \n",
    "        mean_rates_g = rates_df.groupby('id')[numerator_cols].mean()\n",
    "        ids = mean_rates_g.index.values\n",
    "        values = mean_rates_g.values\n",
    "        self.mean_rates_df = pd.concat([pd.DataFrame(ids),\n",
    "                                        pd.DataFrame(values)],axis=1)\n",
    "        self.mean_rates_df.columns = ['id']+['mean_rate_'+i for i in numerator_cols]\n",
    "        \n",
    "        end = time.time()\n",
    "        print('rate finished, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "        \n",
    "    def Ignite(self):\n",
    "        \n",
    "#         self.checkFeatures()\n",
    "        self.Range_Amount()\n",
    "        self.StdVariance()\n",
    "        self.Rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Half an hour!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Volatilities(loan_fillna,amounts_loan)\n",
    "v.Ignite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_stdvar = v.stdvar_df\n",
    "loan_max_amt = v.max_amount\n",
    "loan_min_amt = v.min_amount\n",
    "loan_rate = v.mean_rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_volatility = pd.merge(loan_stdvar,loan_rate,on='id',how='inner')\n",
    "loan_volatility = pd.merge(loan_volatility,loan_max_amt,on='id',how='inner')\n",
    "loan_volatility = pd.merge(loan_volatility,loan_min_amt,on='id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_volatility.to_csv('Loan_processed/loan_volatlity.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del v,loan_volatility,loan_stdvar,loan_max_amt,loan_min_amt,loan_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='link6'>**<font color='darkred'>6. Feature Engineering</font>**</a>\n",
    "- <a id='link6.4'>**6.4 Feature Generation**</a>\n",
    "    - nunique of `financeorg`\n",
    "    - whether `financeorg` contains `浦发`\n",
    "    - `latest24state`:count and max\n",
    "    - `num_of_0`:sum and max\n",
    "    - `state`: whether contain '逾期' and '呆帐'\n",
    "    - sum of amounts of each id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generate():\n",
    "    \n",
    "    def __init__(self,df,types,states,amounts,counts):\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.amounts = amounts\n",
    "        self.types = types\n",
    "        self.states = states\n",
    "        self.counts = counts\n",
    "        self.fts = list(df.columns)\n",
    "        \n",
    "    def checkFeatures(self):\n",
    "        \n",
    "        drop = set(self.amounts)-set(self.fts)\n",
    "        self.amounts = list(set(self.amounts)-drop)  \n",
    "        \n",
    "        drop = set(self.types)-set(self.fts)\n",
    "        self.types = list(set(self.types)-drop)  \n",
    "        \n",
    "        drop = set(self.states)-set(self.fts)\n",
    "        self.states = list(set(self.states)-drop) \n",
    "        \n",
    "        drop = set(self.counts)-set(self.fts)\n",
    "        self.counts = list(set(self.counts)-drop) \n",
    "        \n",
    "    def Num_Records(self):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        g = self.df.groupby('id')['index'].count()\n",
    "        df1 = pd.DataFrame([g.index.values,g.values]).T\n",
    "        df1.columns=['id','num_record']\n",
    "        \n",
    "        self.num_record_df = df1\n",
    "        \n",
    "        end = time.time()\n",
    "        print('Num_record finished, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "        \n",
    "    def n_financeorg(self):\n",
    "        \n",
    "        if 'financeorg' not in self.types:\n",
    "            print('financeorg not kept, skip n_financeorg')\n",
    "            return None\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        financeorg_n = self.df.groupby('id')['financeorg'].nunique()\n",
    "        ids = financeorg_n.index.values\n",
    "        values = financeorg_n.values\n",
    "        self.n_financeorg_df = pd.DataFrame([ids,values]).T\n",
    "        self.n_financeorg_df.columns = ['id','n_financeorg']\n",
    "        \n",
    "        end = time.time()\n",
    "        print('n_financeorg finished, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "        \n",
    "    def pufa_financeorg(self):\n",
    "        \n",
    "        if 'financeorg' not in self.types:\n",
    "            print('financeorg not kept, skip pufa_financeorg')\n",
    "            return None\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        cond = self.df['financeorg']=='浦发银行信用卡中心'\n",
    "        self.df['if_pufa'] = cond*1\n",
    "        g = self.df.groupby('id')['if_pufa'].max()\n",
    "        \n",
    "        ids = g.index.values\n",
    "        values = g.values\n",
    "        \n",
    "        self.if_pufa_df = pd.concat([pd.DataFrame(ids),pd.DataFrame(values)],axis=1)\n",
    "        self.if_pufa_df.columns = ['id','if_pufa']\n",
    "\n",
    "        end = time.time()\n",
    "        print('pufa_financeorg finished, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "        \n",
    "    def n_type(self):\n",
    "        \n",
    "        if 'type' not in self.types:\n",
    "            print('type not kept, skip n_type')\n",
    "            return None\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        n_type = self.df.groupby('id')['financeorg'].nunique()\n",
    "        ids = n_type.index.values\n",
    "        values = n_type.values\n",
    "        self.n_type_df = pd.DataFrame([ids,values]).T\n",
    "        self.n_type_df.columns = ['id','n_types']\n",
    "        \n",
    "        end = time.time()\n",
    "        print('n_types finished, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "        \n",
    "    def n_currency(self):\n",
    "        \n",
    "        if 'currency' not in self.types:\n",
    "            print('currency not kept, skip n_currency')\n",
    "            return None        \n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        n_currency = self.df.groupby('id')['currency'].nunique()\n",
    "        ids = n_currency.index.values\n",
    "        values = n_currency.values\n",
    "        self.n_currency_df = pd.DataFrame([ids,values]).T\n",
    "        self.n_currency_df.columns = ['id','n_currency']\n",
    "        \n",
    "        end = time.time()\n",
    "        print('n_currency finished, time cost {}seconds'.format(np.round(end-start,2)))   \n",
    "        \n",
    "    def n_guaranteetype(self):\n",
    "        \n",
    "        if 'guaranteetype' not in self.types:\n",
    "            print('guaranteetype not kept, skip n_guaranteetype')\n",
    "            return None\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        g = self.df.groupby('id')['guaranteetype'].nunique()\n",
    "        ids = g.index.values\n",
    "        values = g.values\n",
    "        self.n_guaranteetype_df = pd.DataFrame([ids,values]).T\n",
    "        self.n_guaranteetype_df.columns = ['id','n_guaranteetype']\n",
    "        \n",
    "        end = time.time()\n",
    "        print('n_guaranteetype finished, time cost {}seconds'.format(np.round(end-start,2)))  \n",
    "        \n",
    "    def cnt_bad_state(self):\n",
    "        \n",
    "        if 'state' not in self.states:\n",
    "            print('state not kept, skip cnt_bad_state')\n",
    "            return None \n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        #stdcard ['4|销户', '6|未激活', '1|正常', '2|冻结', '3|止付', '5|呆帐']\n",
    "        #loan\n",
    "        \n",
    "        bads = self.df['state'].isin(['2|冻结','5|呆帐','3|止付'])==True\n",
    "        bads = pd.concat([self.df['id'],bads],axis=1)\n",
    "        bads.columns = ['id','cnt_bad']\n",
    "        g = bads.groupby('id')['cnt_bad'].sum()\n",
    "        ids = g.index.values\n",
    "        values = g.values                       \n",
    "        self.cnt_bad_state_df=pd.DataFrame([ids,values]).T\n",
    "        self.cnt_bad_state_df.columns = ['id','cnt_bad']\n",
    "        \n",
    "        end = time.time()\n",
    "        print('cnt_bad_state finished, time cost {}seconds'.format(np.round(end-start,2))) \n",
    "        \n",
    "    def worst_class5state(self):\n",
    "        \n",
    "        if 'class5state' not in self.states:\n",
    "            print('class5state not kept, skip worst_class5state')\n",
    "            return None\n",
    "        \n",
    "        start = time.time()     \n",
    "        \n",
    "        temp = self.df[['id','class5state']]\n",
    "        temp.replace({'1|正常':0,'nothing':1,'9|未知':1,'2|关注':2,'3|次级':3,'4|可疑':4,'5|损失':5},inplace=True)\n",
    "        g = temp.groupby('id')['class5state'].max()\n",
    "        ids = g.index.values\n",
    "        values = g.values\n",
    "        self.worst_class5state_df=pd.DataFrame([ids,values]).T\n",
    "        self.worst_class5state_df.columns = ['id','worst_class5state']        \n",
    "        \n",
    "        cond = self.worst_class5state_df.duplicated(keep='first')==False\n",
    "        self.worst_class5state_df = self.worst_class5state_df.loc[cond]\n",
    "        \n",
    "        end = time.time()\n",
    "        print('worst_class5state finished, time cost {}seconds'.format(np.round(end-start,2)))   \n",
    "        \n",
    "    def cnt_bad_class5state(self):\n",
    "        \n",
    "        if 'class5state' not in self.states:\n",
    "            print('class5state not kept, skip cnt_bad_class5state')\n",
    "            return None\n",
    "        \n",
    "        start = time.time() \n",
    "        \n",
    "        temp = self.df[['id','class5state']]\n",
    "        temp.replace({'1|正常':0,'nothing':1,'9|未知':1,'2|关注':2,'3|次级':3,'4|可疑':4,'5|损失':5},inplace=True)\n",
    "        cond = temp['class5state'].isin([3,4,5])\n",
    "        temp = pd.concat([temp['id'],cond],axis=1)\n",
    "        temp.columns=['id','class5state']\n",
    "        \n",
    "        g = temp.groupby('id')['class5state'].sum()\n",
    "        ids = g.index.values\n",
    "        values = g.values\n",
    "        self.cnt_bad_class5state_df=pd.DataFrame([ids,values]).T\n",
    "        self.cnt_bad_class5state_df.columns = ['id','class5state']\n",
    "        \n",
    "        end = time.time()\n",
    "        print('cnt_bad_class5state finished, time cost {}seconds'.format(np.round(end-start,2)))  \n",
    "        \n",
    "    def sum_curroverduecyc(self):\n",
    "        \n",
    "        if 'curroverduecyc' not in self.counts:\n",
    "            print('curroverduecyc not kept, skip sum_curroverduecyc')\n",
    "            return None    \n",
    "        \n",
    "        start = time.time()        \n",
    "        \n",
    "        g = self.df.groupby('id')['curroverduecyc'].sum()\n",
    "        ids = g.index.values\n",
    "        values = g.values\n",
    "        self.sum_curroverduecyc_df=pd.DataFrame([ids,values]).T\n",
    "        self.sum_curroverduecyc_df.columns = ['id','sum_curroverduecyc']        \n",
    "\n",
    "        end = time.time()\n",
    "        print('sum_curroverduecyc finished, time cost {}seconds'.format(np.round(end-start,2)))  \n",
    "        \n",
    "    def latest24state(self):\n",
    "        \n",
    "        start = time.time()        \n",
    "        \n",
    "        ids = self.df['id'].values\n",
    "        cond = self.df['latest24state'].str.split(pat='',expand=True).fillna('0').replace({'':'0',\n",
    "                                                                                          'D':'0',\n",
    "                                                                                          'C':'0',\n",
    "                                                                                          'N':'0',\n",
    "                                                                                          'G':'0',\n",
    "                                                                                          '/':'0',\n",
    "                                                                                          '*':'0',\n",
    "                                                                                          '#':'0'}).astype('int32')\n",
    "        default_cnt = (cond!=0).sum(axis=1).values\n",
    "        max_default = cond.max(axis=1).values\n",
    "        self.latest24state_df = pd.DataFrame([ids,default_cnt,max_default]).T\n",
    "        self.latest24state_df.columns=['id','cnt_24state','max_24state']\n",
    "        \n",
    "        g1 = self.latest24state_df.groupby('id')['cnt_24state'].sum()\n",
    "        g2 = self.latest24state_df.groupby('id')['max_24state'].max()\n",
    "        \n",
    "        self.latest24state_cnt = pd.DataFrame([g1.index.values,g1.values]).T\n",
    "        self.latest24state_max = pd.DataFrame([g2.index.values,g2.values]).T\n",
    "        \n",
    "        self.latest24state_cnt.columns = ['id','cnt_24state']\n",
    "        self.latest24state_max.columns = ['id','max_24state']\n",
    "        \n",
    "        end = time.time()\n",
    "        print('latest24state finished, time cost {}seconds'.format(np.round(end-start,2)))        \n",
    "        \n",
    "    def SumAmount(self):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        g = self.df.groupby('id')[self.amounts].sum()\n",
    "        ids = pd.DataFrame(g.index.values)\n",
    "        values = g.values\n",
    "        cols = ['sum_'+i for i in self.amounts]\n",
    "        self.sumamount_df = pd.DataFrame(values)\n",
    "        self.sumamount_df = pd.concat([ids,self.sumamount_df],axis=1)\n",
    "        self.sumamount_df.columns = (['id']+cols)\n",
    "        \n",
    "        end = time.time()\n",
    "        print('Sum amount finished, time cost {}seconds'.format(np.round(end-start,2)))                  \n",
    "        \n",
    "    def Ignite(self):\n",
    "        self.checkFeatures()\n",
    "        self.Num_Records()\n",
    "        self.n_financeorg()\n",
    "        self.pufa_financeorg()\n",
    "        self.n_type()\n",
    "        self.n_currency()\n",
    "        self.n_guaranteetype()\n",
    "        self.cnt_bad_state()\n",
    "        self.worst_class5state()\n",
    "        self.cnt_bad_class5state()\n",
    "        self.sum_curroverduecyc()\n",
    "#         self.latest24state()\n",
    "        self.SumAmount()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = Generate(loan_fillna,types_loan,states_loan,amounts_loan,counts_loan)\n",
    "gene.Ignite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene.latest24state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_gene = gene.n_financeorg_df\n",
    "loan_gene = pd.merge(left=loan_gene,right=gene.num_record_df,on='id',how='inner')\n",
    "loan_gene = pd.merge(left=loan_gene,right=gene.if_pufa_df,on='id',how='inner')\n",
    "loan_gene = pd.merge(left=loan_gene,right=gene.n_type_df,on='id',how='inner')\n",
    "loan_gene = pd.merge(left=loan_gene,right=gene.n_currency_df,on='id',how='inner')\n",
    "loan_gene = pd.merge(left=loan_gene,right=gene.n_guaranteetype_df,on='id',how='inner')\n",
    "loan_gene = pd.merge(left=loan_gene,right=gene.cnt_bad_state_df,on='id',how='inner')\n",
    "loan_gene = pd.merge(left=loan_gene,right=gene.worst_class5state_df,on='id',how='inner')\n",
    "loan_gene = pd.merge(left=loan_gene,right=gene.cnt_bad_class5state_df,on='id',how='inner')\n",
    "loan_gene = pd.merge(left=loan_gene,right=gene.sum_curroverduecyc_df,on='id',how='inner')\n",
    "loan_gene = pd.merge(left=loan_gene,right=gene.sumamount_df,on='id',how='inner')\n",
    "# card_gene = pd.merge(left=card_gene,right=gene.latest24state_df,on='id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_gene.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_gene.to_csv('Loan_processed/loan_gene.csv',index=False,encoding='GBK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loan_gene,gene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time Related Features**\n",
    "- **4300seconds!!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRelated():\n",
    "    \n",
    "    def __init__(self,df,types,states,amounts,counts):\n",
    "        \n",
    "        self.whole_df = df.copy()\n",
    "        self.amounts = amounts\n",
    "        self.types = types\n",
    "        self.states = states\n",
    "        self.counts = counts\n",
    "        self.df = self.whole_df[['id','index','opendate']+self.amounts]\n",
    "        \n",
    "    def Convert(self):\n",
    "        \n",
    "        self.df = self.df\n",
    "        self.df['opendate2'] = pd.to_datetime(self.df['opendate'])\n",
    "        self.df.drop('opendate',axis=1,inplace=True)\n",
    "        self.fts = list(self.df.columns)\n",
    "        \n",
    "    def cutDF(self):\n",
    "        \n",
    "        start = time.time()\n",
    "        g1 = self.df.groupby('id')\n",
    "        \n",
    "        \n",
    "        latest_g = g1.apply(lambda x:x.sort_values('opendate2',ascending=False).head(1))\n",
    "        print('latest records finished')\n",
    "        print()\n",
    "        \n",
    "        latest_3_g = g1.apply(lambda x:x.sort_values('opendate2',ascending=False).head(3))\n",
    "        print('latest 3 records finished')\n",
    "        print()\n",
    "        \n",
    "        latest_6_g = g1.apply(lambda x:x.sort_values('opendate2',ascending=False).head(6))\n",
    "        print('latest 6 records finished')\n",
    "        print()\n",
    "        \n",
    "        self.latest_df = pd.DataFrame(latest_g.values)\n",
    "        self.latest_3_df = pd.DataFrame(latest_3_g.values)\n",
    "        self.latest_6_df = pd.DataFrame(latest_6_g.values)\n",
    "        \n",
    "        \n",
    "        self.latest_df.columns = self.fts\n",
    "        self.latest_3_df.columns = self.fts\n",
    "        self.latest_6_df.columns = self.fts\n",
    "        \n",
    "        self.latest_df.iloc[:,1:] = self.latest_df.iloc[:,1:].astype(int)\n",
    "        self.latest_3_df.iloc[:,1:] = self.latest_3_df.iloc[:,1:].astype(int)\n",
    "        self.latest_6_df.iloc[:,1:] = self.latest_6_df.iloc[:,1:].astype(int)\n",
    "        \n",
    "        end = time.time()\n",
    "        print('DF has been cut, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "        \n",
    "    def SumAmounts(self):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        print('start sum')\n",
    "        sum3_g = self.latest_3_df.groupby('id')[self.amounts].sum()\n",
    "        sum6_g = self.latest_6_df.groupby('id')[self.amounts].sum()\n",
    "        \n",
    "        id3 = pd.DataFrame(sum3_g.index.values)\n",
    "        id6 = pd.DataFrame(sum6_g.index.values)\n",
    "\n",
    "        values3 = pd.DataFrame(sum3_g.values)\n",
    "        values6 = pd.DataFrame(sum6_g.values)\n",
    "        \n",
    "        cols3 = ['sum_'+i+'_3' for i in self.amounts]\n",
    "        cols6 = ['sum_'+i+'_6' for i in self.amounts]\n",
    "        \n",
    "        self.sumamount_df3 = pd.concat([id3,values3],axis=1)\n",
    "        self.sumamount_df6 = pd.concat([id6,values6],axis=1)\n",
    "        \n",
    "        self.sumamount_df3.columns = (['id']+cols3)\n",
    "        self.sumamount_df6.columns = (['id']+cols6)\n",
    "        \n",
    "        end1 = time.time()\n",
    "        print('sum finished, time cost {}seconds'.format(np.round(end1-start,2)))\n",
    "        print()\n",
    "        \n",
    "    def MeanAmounts(self): \n",
    "        \n",
    "        start = time.time()\n",
    "        print('start mean')\n",
    "        mean3_g = self.latest_3_df.groupby('id')[self.amounts].mean()\n",
    "        mean6_g = self.latest_6_df.groupby('id')[self.amounts].mean()\n",
    "        \n",
    "        id3 = pd.DataFrame(mean3_g.index.values)\n",
    "        id6 = pd.DataFrame(mean6_g.index.values)\n",
    "\n",
    "        values3 = pd.DataFrame(mean3_g.values)\n",
    "        values6 = pd.DataFrame(mean6_g.values)\n",
    "        \n",
    "        cols3 = ['mean_'+i+'_3' for i in self.amounts]\n",
    "        cols6 = ['mean_'+i+'_6' for i in self.amounts]\n",
    "        \n",
    "        self.meanamount_df3 = pd.concat([id3,values3],axis=1)\n",
    "        self.meanamount_df6 = pd.concat([id6,values6],axis=1)\n",
    "        \n",
    "        self.meanamount_df3.columns = (['id']+cols3)\n",
    "        self.meanamount_df6.columns = (['id']+cols6)\n",
    "        \n",
    "        end1 = time.time()\n",
    "        print('mean finished, time cost {}seconds'.format(np.round(end1-start,2)))\n",
    "        print()\n",
    "    \n",
    "    def NumRecords(self):\n",
    "        \n",
    "        start = time.time()\n",
    "        print('start record')\n",
    "        num3_g = self.latest_3_df.groupby('id')['index'].count()\n",
    "        num6_g = self.latest_6_df.groupby('id')['index'].count()\n",
    "        \n",
    "        id3 = pd.DataFrame(num3_g.index.values)\n",
    "        id6 = pd.DataFrame(num6_g.index.values)\n",
    "\n",
    "        values3 = pd.DataFrame(num3_g.values)\n",
    "        values6 = pd.DataFrame(num6_g.values)\n",
    "        \n",
    "        cols3 = ['num_record_3']\n",
    "        cols6 = ['num_record_6']\n",
    "        \n",
    "        self.numrecord_df3 = pd.concat([id3,values3],axis=1)\n",
    "        self.numrecord_df6 = pd.concat([id6,values6],axis=1)\n",
    "        \n",
    "        self.numrecord_df3.columns = (['id']+cols3)\n",
    "        self.numrecord_df6.columns = (['id']+cols6)\n",
    "        \n",
    "        end1 = time.time()\n",
    "        print('numrecord finished, time cost {}seconds'.format(np.round(end1-start,2)))\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mwei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/mwei/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest records finished\n",
      "\n",
      "latest 3 records finished\n",
      "\n",
      "latest 6 records finished\n",
      "\n",
      "DF has been cut, time cost 4286.15seconds\n"
     ]
    }
   ],
   "source": [
    "a = TimeRelated(loan_fillna,types_loan,states_loan,amounts_loan,counts_loan)\n",
    "a.Convert()\n",
    "a.cutDF() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sum\n",
      "sum finished, time cost 6.58seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.SumAmounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start mean\n",
      "mean finished, time cost 6.36seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.MeanAmounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start record\n",
      "numrecord finished, time cost 5.15seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.NumRecords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sum_creditlimitamount_6</th>\n",
       "      <th>sum_balance_6</th>\n",
       "      <th>sum_scheduledpaymentamount_6</th>\n",
       "      <th>sum_actualpaymentamount_6</th>\n",
       "      <th>sum_curroverdueamount_6</th>\n",
       "      <th>sum_overdue31to60amount_6</th>\n",
       "      <th>sum_overdue61to90amount_6</th>\n",
       "      <th>sum_overdue91to180amount_6</th>\n",
       "      <th>sum_overdueover180amount_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001690617d31704261808cee46c21d</td>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001fa8a2f1407958617d40ccf5289b</td>\n",
       "      <td>8200</td>\n",
       "      <td>4290</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000029dd22864abc4062ae0cb8b0b779</td>\n",
       "      <td>270000</td>\n",
       "      <td>270000</td>\n",
       "      <td>2595</td>\n",
       "      <td>2595</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000032d505d98892988d1900869bf1be</td>\n",
       "      <td>49600</td>\n",
       "      <td>28851</td>\n",
       "      <td>8254</td>\n",
       "      <td>8254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00003e25c0754ca7a89f10a3a0f1958b</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758216</th>\n",
       "      <td>ffff0e693b759e7177cb0dd1404884ad</td>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758217</th>\n",
       "      <td>ffff3db7a932f36e9b550a6fe0f97fc3</td>\n",
       "      <td>2499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758218</th>\n",
       "      <td>ffff7d672362f5bcb25aa5063b9b44b7</td>\n",
       "      <td>8800</td>\n",
       "      <td>6698</td>\n",
       "      <td>460</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758219</th>\n",
       "      <td>ffff7f01f127afeabdee0e5fb605d2a3</td>\n",
       "      <td>34800</td>\n",
       "      <td>20033</td>\n",
       "      <td>2463</td>\n",
       "      <td>2463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758220</th>\n",
       "      <td>ffff93d6af18402d46a68fd8a7d5237e</td>\n",
       "      <td>46000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>758221 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  sum_creditlimitamount_6  \\\n",
       "0       00001690617d31704261808cee46c21d                      898   \n",
       "1       00001fa8a2f1407958617d40ccf5289b                     8200   \n",
       "2       000029dd22864abc4062ae0cb8b0b779                   270000   \n",
       "3       000032d505d98892988d1900869bf1be                    49600   \n",
       "4       00003e25c0754ca7a89f10a3a0f1958b                    10000   \n",
       "...                                  ...                      ...   \n",
       "758216  ffff0e693b759e7177cb0dd1404884ad                      877   \n",
       "758217  ffff3db7a932f36e9b550a6fe0f97fc3                     2499   \n",
       "758218  ffff7d672362f5bcb25aa5063b9b44b7                     8800   \n",
       "758219  ffff7f01f127afeabdee0e5fb605d2a3                    34800   \n",
       "758220  ffff93d6af18402d46a68fd8a7d5237e                    46000   \n",
       "\n",
       "        sum_balance_6  sum_scheduledpaymentamount_6  \\\n",
       "0                   0                             0   \n",
       "1                4290                           483   \n",
       "2              270000                          2595   \n",
       "3               28851                          8254   \n",
       "4               10000                             0   \n",
       "...               ...                           ...   \n",
       "758216              0                             0   \n",
       "758217              0                             0   \n",
       "758218           6698                           460   \n",
       "758219          20033                          2463   \n",
       "758220              0                             0   \n",
       "\n",
       "        sum_actualpaymentamount_6  sum_curroverdueamount_6  \\\n",
       "0                               0                        0   \n",
       "1                             483                        0   \n",
       "2                            2595                        0   \n",
       "3                            8254                        0   \n",
       "4                               0                        0   \n",
       "...                           ...                      ...   \n",
       "758216                          0                        0   \n",
       "758217                          0                        0   \n",
       "758218                        460                        0   \n",
       "758219                       2463                        0   \n",
       "758220                          0                        0   \n",
       "\n",
       "        sum_overdue31to60amount_6  sum_overdue61to90amount_6  \\\n",
       "0                               0                          0   \n",
       "1                               0                          0   \n",
       "2                               0                          0   \n",
       "3                               0                          0   \n",
       "4                               0                          0   \n",
       "...                           ...                        ...   \n",
       "758216                          0                          0   \n",
       "758217                          0                          0   \n",
       "758218                          0                          0   \n",
       "758219                          0                          0   \n",
       "758220                          0                          0   \n",
       "\n",
       "        sum_overdue91to180amount_6  sum_overdueover180amount_6  \n",
       "0                                0                           0  \n",
       "1                                0                           0  \n",
       "2                                0                           0  \n",
       "3                                0                           0  \n",
       "4                                0                           0  \n",
       "...                            ...                         ...  \n",
       "758216                           0                           0  \n",
       "758217                           0                           0  \n",
       "758218                           0                           0  \n",
       "758219                           0                           0  \n",
       "758220                           0                           0  \n",
       "\n",
       "[758221 rows x 10 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_df,sumamount_df3,sumamount_df6,meanamount_df3,meanamount_df6,numrecord_df3,numrecord_df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='link6'>**<font color='darkred'>6. Feature Engineering</font>**</a>\n",
    "- <a id='link6.5'>**6.5 Cross \\& Dot Products**</a>\n",
    "    - **DON'T USE FINANCEORG! THIS IS HORIFFYING!!**\n",
    "    - **<font color='green'>Function: Combine less frequnt values</font>**\n",
    "    - **<font color='green'>The columns need to be OneHot are `financetype`, `type`, `state`,`currency`,`class5state` and `guaranteetype`</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjCrossAmounts():\n",
    "    \n",
    "    def __init__(self,df,obj_cols,amounts,combi_per,warning=60):\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.obj_cols = obj_cols\n",
    "        self.amounts = amounts\n",
    "        self.combi_per = combi_per\n",
    "        self.fts = self.df.columns\n",
    "        self.warning = warning\n",
    "        self.n = df.shape[0]\n",
    "        \n",
    "    def checkFeatures(self):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        drop = set(self.obj_cols)-set(self.fts)\n",
    "        self.obj_cols = list(set(self.obj_cols)-drop)\n",
    "\n",
    "        drop = set(self.amounts)-set(self.fts)\n",
    "        self.amounts = list(set(self.amounts)-drop)        \n",
    "\n",
    "        end = time.time()\n",
    "    \n",
    "        print('Features Checking Finished, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "        print()\n",
    "        \n",
    "    def MergeLowFrequency(self,nunique_thres=5):\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        # to record what values are combined in obj_cols\n",
    "        self.replace_record = {}\n",
    "        \n",
    "        for i in self.obj_cols:\n",
    "            \n",
    "            if self.df[i].nunique()<=nunique_thres:\n",
    "                print('feature #{}# nunique is less than {}, no need to be merged'.format(i,nunique_thres))\n",
    "                print()\n",
    "                continue\n",
    "                \n",
    "            print('now merging feature #{}#'.format(i))    \n",
    "            print()\n",
    "            v_C = self.df[i].value_counts(sort=False)\n",
    "            thres = v_C.quantile(self.combi_per)\n",
    "            cond = v_C<=thres\n",
    "            to_replace = v_C.loc[cond].index.values\n",
    "            self.replace_record[i] = to_replace\n",
    "            self.df[i] = self.df[i].replace(to_replace,'combi_'+i)\n",
    "            \n",
    "        end = time.time()\n",
    "        print('Merging Low-Frequency Values Finished, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "        print()\n",
    "        \n",
    "    def ObjCombination(self):\n",
    "        \n",
    "        # generate a new column to restore combination\n",
    "        start = time.time()\n",
    "        self.df['obj_cross'] = '_vs_'\n",
    "        \n",
    "        # generate a column for combinations\n",
    "        self.df['obj_cross'] = self.df['obj_cross']+self.df[self.obj_cols].astype(str).sum(axis=1)\n",
    "        \n",
    "#         for i in self.obj_cols:\n",
    "#             self.df['obj_cross'] = self.df['obj_cross']+self.df[i]\n",
    "        \n",
    "        # extract 'id' and 'obj_cross' columns as a new dataframe\n",
    "        # following used for amount vs. categorical\n",
    "        self.combi_df = self.df[['id','obj_cross']]\n",
    "        self.combi_df['obj_cross'].fillna('nothing',inplace=True)\n",
    "        self.unique_combi = self.df['obj_cross'].unique()\n",
    "        self.m = len(self.unique_combi)\n",
    "        \n",
    "        assert self.m<=self.warning, print(\"Warning: too many combinations, total {}, try to set larger threshold\".format(self.m))\n",
    "        end = time.time()\n",
    "        print('Objectives Combination Finished, time cost {}seconds'.format(np.round(end-start,2)))  \n",
    "        print()\n",
    "        \n",
    "    def ColGeneration(self):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        onehot_matrix = np.zeros((self.n,self.m))\n",
    "        combi_col = self.combi_df['obj_cross'].values\n",
    "        for i in range(self.n):\n",
    "            pos = np.where(self.unique_combi==combi_col[i])[0][0]\n",
    "            onehot_matrix[i,pos] = 1\n",
    "        \n",
    "#         OneHot_df = pd.DataFrame(empty_matrix,columns=self.unique_combi)\n",
    "#         self.combi_df = pd.concat([self.combi_df,OneHot_df],axis=1)\n",
    "        \n",
    "        self.onehot_matrix = onehot_matrix\n",
    "        \n",
    "        end = time.time()\n",
    "        print('One-Hot Columns Generation Finished, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "        print()\n",
    "        \n",
    "    def DotProduct(self,amount_col):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        amount_values = self.df[amount_col].values\n",
    "        amount_cross_onehot = self.onehot_matrix*amount_values[:,np.newaxis]\n",
    "        \n",
    "#         columns = ['_'.join([amount_col,i]) for i in self.unique_combi]\n",
    "        columns = [amount_col+i for i in self.unique_combi]\n",
    "        \n",
    "        df = pd.DataFrame(amount_cross_onehot,columns=columns)\n",
    "        self.combi_df = pd.concat([self.combi_df,df],axis=1)\n",
    "        \n",
    "        end = time.time()\n",
    "        print('Amount Col {} VS One-Hot Dot Products Finished, time cost {}seconds'.format(amount_col,np.round(end-start,2)))\n",
    "        print()\n",
    "    \n",
    "    def CompressMultipleIDs(self):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        sum_cols = list(self.combi_df.columns)\n",
    "        sum_cols.remove('id')\n",
    "        sum_cols.remove('obj_cross')\n",
    "        \n",
    "        grouped = self.combi_df.groupby('id')[sum_cols].sum()\n",
    "        IDs = pd.DataFrame(grouped.index.values,columns=['id'])\n",
    "        Values = pd.DataFrame(grouped.values,columns=sum_cols)\n",
    "        self.compressed_df = pd.concat([IDs,Values],axis=1)\n",
    "        \n",
    "        end = time.time()\n",
    "        print('Compress Multiple ID Records to One Finished, time cost {}seconds'.format(np.round(end-start,2)))\n",
    "        print()        \n",
    "    \n",
    "    def Ignite(self):\n",
    "        \n",
    "        start = time.time()\n",
    "        self.checkFeatures()\n",
    "        self.MergeLowFrequency()\n",
    "        self.ObjCombination()\n",
    "        self.ColGeneration()\n",
    "        \n",
    "        for i in self.amounts:\n",
    "            self.DotProduct(i)\n",
    "        \n",
    "        self.CompressMultipleIDs()\n",
    "        \n",
    "        end = time.time()\n",
    "        print('Whole Procedure Finished, time cost {}seconds'.format(np.round(end-start,2))) \n",
    "        print()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_loan+states_loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = ['financetype','type','currency','guaranteetype','state','class5state']\n",
    "\n",
    "loan_cross = ObjCrossAmounts(df = loan_fillna,\n",
    "                             obj_cols = ['financetype'],\n",
    "                             amounts=amounts_loan,\n",
    "                             combi_per=0.05)\n",
    "loan_cross.Ignite()\n",
    "loan_dot_pro1 = loan_cross.compressed_df\n",
    "col_name =[i + obj_cols[0] for i in list(loan_dot_pro1.columns)[1:]]  #[1:] to exclude id\n",
    "col_name = ['id']+col_name # put back 'id'\n",
    "loan_dot_pro1.columns = col_name\n",
    "del loan_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dot_pro1.to_csv('Loan_processed/loan_cross1.csv',index=False,encoding='GBK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loan_dot_pro1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = ['financetype','type','currency','guaranteetype','state','class5state']\n",
    "\n",
    "loan_cross = ObjCrossAmounts(df = loan_fillna,\n",
    "                               obj_cols = ['type'],\n",
    "                               amounts=amounts_loan,\n",
    "                               combi_per=0.05)\n",
    "loan_cross.Ignite()\n",
    "loan_dot_pro2 = loan_cross.compressed_df\n",
    "col_name =[i + obj_cols[1] for i in list(loan_dot_pro2.columns)[1:]]  #[1:] to exclude id\n",
    "col_name = ['id']+col_name # put back 'id'\n",
    "loan_dot_pro2.columns = col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dot_pro2.to_csv('Loan_processed/loan_cross2.csv',index=False,encoding='GBK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loan_dot_pro2,loan_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = ['financetype','type','currency','guaranteetype','state','class5state']\n",
    "\n",
    "loan_cross = ObjCrossAmounts(df = loan_fillna,\n",
    "                             obj_cols = ['currency'],\n",
    "                             amounts=amounts_loan,\n",
    "                             combi_per=0.05)\n",
    "loan_cross.Ignite()\n",
    "loan_dot_pro3 = loan_cross.compressed_df\n",
    "col_name =[i + obj_cols[2] for i in list(loan_dot_pro3.columns)[1:]]  #[1:] to exclude id\n",
    "col_name = ['id']+col_name # put back 'id'\n",
    "loan_dot_pro3.columns = col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dot_pro3.to_csv('Loan_processed/loan_cross3.csv',index=False,encoding='GBK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loan_cross,loan_dot_pro3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obj_cols = ['financetype','type','currency','guaranteetype','state','class5state']\n",
    "\n",
    "loan_cross = ObjCrossAmounts(df = loan_fillna,\n",
    "                             obj_cols = ['guaranteetype'],\n",
    "                             amounts=amounts_loan,\n",
    "                             combi_per=0.05)\n",
    "loan_cross.Ignite()\n",
    "loan_dot_pro4 = loan_cross.compressed_df\n",
    "col_name =[i + obj_cols[3] for i in list(loan_dot_pro4.columns)[1:]]  #[1:] to exclude id\n",
    "col_name = ['id']+col_name # put back 'id'\n",
    "loan_dot_pro4.columns = col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dot_pro4.to_csv('Loan_processed/loan_cross4.csv',index=False,encoding='GBK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loan_cross,loan_dot_pro4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obj_cols = ['financetype','type','currency','guaranteetype','state','class5state']\n",
    "\n",
    "loan_cross = ObjCrossAmounts(df = loan_fillna,\n",
    "                               obj_cols = ['state'],\n",
    "                               amounts=amounts_loan,\n",
    "                               combi_per=0.05)\n",
    "loan_cross.Ignite()\n",
    "loan_dot_pro5 = loan_cross.compressed_df\n",
    "col_name =[i + obj_cols[4] for i in list(loan_dot_pro5.columns)[1:]]  #[1:] to exclude id\n",
    "col_name = ['id']+col_name # put back 'id'\n",
    "loan_dot_pro5.columns = col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dot_pro5.to_csv('Loan_processed/loan_cross5.csv',index=False,encoding='GBK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loan_cross,loan_dot_pro5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = ['financetype','type','currency','guaranteetype','state','class5state']\n",
    "\n",
    "loan_cross = ObjCrossAmounts(df = loan_fillna,\n",
    "                               obj_cols = ['class5state'],\n",
    "                               amounts=amounts_loan,\n",
    "                               combi_per=0.05)\n",
    "loan_cross.Ignite()\n",
    "loan_dot_pro6 = loan_cross.compressed_df\n",
    "col_name =[i + obj_cols[5] for i in list(loan_dot_pro6.columns)[1:]]  #[1:] to exclude id\n",
    "col_name = ['id']+col_name # put back 'id'\n",
    "loan_dot_pro6.columns = col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dot_pro6.to_csv('Loan_processed/loan_cross6.csv',index=False,encoding='GBK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loan_cross,loan_dot_pro6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
